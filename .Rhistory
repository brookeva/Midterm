libraries(jsonlite)
library(jsonlite)
library(geojsonsf)
library(sf)
library(geojsonsf)
library(sf)
NC_Data1 = geojsonsf::geojson_sf("https://raw.githubusercontent.com/mafichman/MUSA_508_Lab/main/Midterm/data/2022/studentData.geojson")
st_read("https://raw.githubusercontent.com/mafichman/MUSA_508_Lab/main/Midterm/data/2022/studentData.geojson")
NC_Data = st_read("https://raw.githubusercontent.com/mafichman/MUSA_508_Lab/main/Midterm/data/2022/studentData.geojson")
view(NC_Data)
head(NC_Data)
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory"
NC_Data = st_read("https://raw.githubusercontent.com/mafichman/MUSA_508_Lab/main/Midterm/data/2022/studentData.geojson")
head(NC_Data)
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory"
NC_Data = st_read("https://raw.githubusercontent.com/mafichman/MUSA_508_Lab/main/Midterm/data/2022/studentData.geojson")
head(NC_Data)
st_transform('ESRI:102286')
Proximity.to.Public.Transportation <- read.csv("~/GitHub/Midterm/Proximity to Public Transportation.geojson", header=FALSE)
View(Proximity.to.Public.Transportation)
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory"
NC_Data = st_read("https://raw.githubusercontent.com/mafichman/MUSA_508_Lab/main/Midterm/data/2022/studentData.geojson")
head(NC_Data)
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
prox_transit <-
st_read("Proximity.to.Public.Transportation") %>%
st_transform('ESRI:102286')
View(NC_Data)
View(NC_Data)
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory"
NC_Data = st_read("https://raw.githubusercontent.com/mafichman/MUSA_508_Lab/main/Midterm/data/2022/studentData.geojson")
head(NC_Data)
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
NC_Data.sf <-
NC_Data %>%
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102286')
View(NC_Data)
# finding counts by group
NC_Data %>%
group_by(bldggrade) %>%
summarize(count = n()) %>%
arrange(-count) %>% top_n(10) %>%
kable() %>%
kable_styling()
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory"
NC_Data = st_read("https://raw.githubusercontent.com/mafichman/MUSA_508_Lab/main/Midterm/data/2022/studentData.geojson")
head(NC_Data)
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
NC_Data.sf <-
NC_Data %>%
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102286')
## NC_Crimes <- read.csv(file.path(root.dir,"/Chapter3_4/bostonCrimes.csv"))
# finding counts by group
NC_Data %>%
group_by(bldggrade) %>%
summarize(count = n()) %>%
arrange(-count) %>% top_n(10) %>%
kable() %>%
kable_styling()
# finding counts by group
NC_Data %>%
group_by(fireplaces) %>%
summarize(count = n()) %>%
arrange(-count) %>% top_n(10) %>%
kable() %>%
kable_styling()
# finding counts by group
NC_Data %>%
group_by(bldggrade) %>%
summarize(count = n()) %>%
arrange(-count) %>% top_n(10) %>%
kable() %>%
kable_styling()
# finding counts by group
NC_Data %>%
group_by(bldggrade) %>%
summarize(count = n()) %>%
arrange(-count) %>%
top_n(10) %>%
kable() %>%
kable_styling()
NC_Data %>%
group_by(bldggrade)
NC_Data %>%
group_by(bldggrade) %>%
summarize(count = n())
NC_Data %>%
group_by(bldggrade) %>%
summarize(count = n()) %>%
arrange(-count)
# finding counts by group
NC_Data %>%
group_by(bldggrade) %>%
summarize(count = n()) %>%
arrange(-count) %>%
top_n(10)
# finding counts by group
NC_Data %>%
group_by(bldggrade) %>%
summarize(count = n()) %>%
arrange(-count)
?top+n
?top_n
# finding counts by group
NC_Data %>%
group_by(bldggrade) %>%
summarize(count = n()) %>%
arrange(-count) %>%
head(10) %>%
kable() %>%
kable_styling()
# finding counts by group
NC_Data %>%
group_by(bldggrade) %>%
st_drop_geometry() %>%
summarize(count = n()) %>%
arrange(-count) %>%
head(10) %>%
kable() %>%
kable_styling()
ggplot() +
geom_sf(data = NC_Data, fill = "grey40") +
geom_sf(data = NC_Data.sf, aes(colour = q5(PricePerSq)),
show.legend = "point", size = .75) +
scale_colour_manual(values = palette5,
labels=qBr(NC,"PricePerSq"),
name="Quintile\nBreaks") +
labs(title="Price Per Square Foot, North Carolina") +
mapTheme()
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory"
NC_Data = st_read("https://raw.githubusercontent.com/mafichman/MUSA_508_Lab/main/Midterm/data/2022/studentData.geojson")
head(NC_Data)
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
NC_Data.sf <-
NC_Data %>%
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102286')
## NC_Crimes <- read.csv(file.path(root.dir,"/Chapter3_4/bostonCrimes.csv"))
# finding counts by group
NC_Data %>%
group_by(bldggrade) %>%
st_drop_geometry() %>%
summarize(count = n()) %>%
arrange(-count) %>%
head(10) %>%
kable() %>%
kable_styling()
# ggplot, reorder
# Mapping data
ggplot() +
geom_sf(data = NC_Data, fill = "grey40") +
geom_sf(data = NC_Data.sf, aes(colour = q5(PricePerSq)),
show.legend = "point", size = .75) +
scale_colour_manual(values = palette5,
labels=qBr(NC,"PricePerSq"),
name="Quintile\nBreaks") +
labs(title="Price Per Square Foot, North Carolina") +
mapTheme()
# ggplot, reorder
# Mapping data
ggplot() +
geom_sf(data = NC_Data, fill = "grey40") +
geom_sf(data = NC_Data.sf, aes(colour = q5(Price)),
show.legend = "point", size = .75) +
scale_colour_manual(values = palette5,
labels=qBr(NC,"Price"),
name="Quintile\nBreaks") +
labs(title="Price Per Square Foot, North Carolina") +
mapTheme()
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
nhoods <-
st_read("http://bostonopendata-boston.opendata.arcgis.com/datasets/3525b0ee6e6b427f9aab5d0a1d0a1a28_0.geojson") %>%
st_transform('ESRI:102286')
boston <-
read.csv(file.path(root.dir,"/Chapter3_4/bostonHousePriceData_clean.csv"))
boston.sf <-
boston %>%
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102286')
bostonCrimes <- read.csv(file.path(root.dir,"/Chapter3_4/bostonCrimes.csv"))
# finding counts by group
bostonCrimes %>%
group_by(OFFENSE_CODE_GROUP) %>%
summarize(count = n()) %>%
arrange(-count) %>% top_n(10) %>%
kable() %>%
kable_styling()
# ggplot, reorder
# Mapping data
ggplot() +
geom_sf(data = nhoods, fill = "grey40") +
geom_sf(data = boston.sf, aes(colour = q5(PricePerSq)),
show.legend = "point", size = .75) +
scale_colour_manual(values = palette5,
labels=qBr(boston,"PricePerSq"),
name="Quintile\nBreaks") +
labs(title="Price Per Square Foot, Boston") +
mapTheme()
# ggplot, reorder
# Mapping data
ggplot() +
geom_sf(data = NC_Data, fill = "grey40") +
geom_sf(data = NC_Data.sf, aes(colour = q5(Price)),
show.legend = "point", size = .75) +
scale_colour_manual(values = palette5,
labels= qBr(NC,"Price"),
name="Quintile\nBreaks") +
labs(title="Price Per Square Foot, North Carolina") +
mapTheme()
# ggplot, reorder
# Mapping data
ggplot() +
geom_sf(data = NC_Data, fill = "grey40") +
geom_sf(data = NC_Data.sf, aes(colour = q5(Price)),
show.legend = "point", size = .75) +
scale_colour_manual(values = palette5,
labels= qBr(NC_Data,"Price"),
name="Quintile\nBreaks") +
labs(title="Price Per Square Foot, North Carolina") +
mapTheme()
# ggplot, reorder
# Mapping data
ggplot() +
geom_sf(data = NC_Data, fill = "grey40") +
geom_sf(data = NC_Data.sf, aes(colour = q5(Price)),
show.legend = "point", size = .75) +
scale_colour_manual(values = palette5,
labels= qBr(NC_Data, "Price"),
name="Quintile\nBreaks") +
labs(title="Price Per Square Foot, North Carolina") +
mapTheme()
# ggplot, reorder
# Mapping data
ggplot() +
geom_sf(data = NC_Data, fill = "grey40") +
geom_sf(data = NC_Data.sf, aes(colour = q5(Price)),
show.legend = "point", size = .75) +
scale_colour_manual(values = palette5,
labels= qBr(NC_Data, "price"),
name="Quintile\nBreaks") +
labs(title="Price Per Square Foot, North Carolina") +
mapTheme()
# ggplot, reorder
# Mapping data
ggplot() +
geom_sf(data = NC_Data, fill = "grey40") +
geom_sf(data = NC_Data.sf, aes(colour = q5(price)),
show.legend = "point", size = .75) +
scale_colour_manual(values = palette5,
labels= qBr(NC_Data, "price"),
name="Quintile\nBreaks") +
labs(title="Price Per Square Foot, North Carolina") +
mapTheme()
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory"
NC_Data = st_read("https://raw.githubusercontent.com/mafichman/MUSA_508_Lab/main/Midterm/data/2022/studentData.geojson")
head(NC_Data)
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
#nhoods <-
#st_read("http://bostonopendata-boston.opendata.arcgis.com/datasets/3525b0ee6e6b427f9aab5d0a1d0a1a28_0.geojson") %>%
# st_transform('ESRI:102286')
#boston <-
#read.csv(file.path(root.dir,"/Chapter3_4/bostonHousePriceData_clean.csv"))
NCData.sf <-
NC_Data %>%
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102286')
#bostonCrimes <- read.csv(file.path(root.dir,"/Chapter3_4/bostonCrimes.csv"))
# finding counts by group
NC_Data %>%
group_by(bldggrade) %>%
summarize(count = n()) %>%
arrange(-count) %>% top_n(10) %>%
kable() %>%
kable_styling()
# finding counts by group
NC_Data %>%
group_by(bldggrade) %>%
summarize(count = n()) %>%
arrange(-count) %>% top_n(10) %>%
kable() %>%
kable_styling()
NC_Data %>%
group_by(bldggrade)
NC_Data %>%
group_by(bldggrade) %>%
summarize(count = n())
NC_Data %>%
group_by(bldggrade) %>%
summarize(count = n()) %>%
arrange(-count) %>% top_n(10)
## Home Features cor
st_drop_geometry(NCData.sf) %>%
mutate(Age = 2022 - yearbuilt) %>%
dplyr::select(price, heatedarea, Age, shape_Area) %>%
filter(price <= 1000000, Age < 500) %>%
gather(Variable, Value, -price) %>%
ggplot(aes(Value, price)) +
geom_point(size = .5) + geom_smooth(method = "lm", se=F, colour = "#FA7800") +
facet_wrap(~Variable, ncol = 3, scales = "free") +
labs(title = "Price as a function of continuous variables") +
plotTheme()
## Crime cor
NCData.sf %>%
st_drop_geometry() %>%
mutate(Age = 2015 - YR_BUILT) %>%
dplyr::select(SalePrice, starts_with("crime_")) %>%
filter(SalePrice <= 1000000) %>%
gather(Variable, Value, -SalePrice) %>%
ggplot(aes(Value, SalePrice)) +
geom_point(size = .5) + geom_smooth(method = "lm", se=F, colour = "#FA7800") +
facet_wrap(~Variable, nrow = 1, scales = "free") +
labs(title = "Price as a function of continuous variables") +
plotTheme()
View(NC_Data.sf)
NCData.test <- NCData.sf[-inTrain,]
inTrain <- createDataPartition(
y = paste(NCData.sf$Name, NCData.sf$NUM_FLOORS.cat,
NCData.sf$Style, NCData.sf$R_AC),
p = .60, list = FALSE)
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory"
NC_Data = st_read("https://raw.githubusercontent.com/mafichman/MUSA_508_Lab/main/Midterm/data/2022/studentData.geojson")
head(NC_Data)
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
#nhoods <-
#st_read("http://bostonopendata-boston.opendata.arcgis.com/datasets/3525b0ee6e6b427f9aab5d0a1d0a1a28_0.geojson") %>%
# st_transform('ESRI:102286')
#boston <-
#read.csv(file.path(root.dir,"/Chapter3_4/bostonHousePriceData_clean.csv"))
NCData.sf <-
NC_Data %>%
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102286')
#bostonCrimes <- read.csv(file.path(root.dir,"/Chapter3_4/bostonCrimes.csv"))
# finding counts by group
NC_Data %>%
group_by(bldggrade) %>%
summarize(count = n()) %>%
arrange(-count) %>% top_n(10) %>%
kable() %>%
kable_styling()
inTrain <- createDataPartition(
y = paste(NCData.sf$Name, NCData.sf$NUM_FLOORS.cat,
NCData.sf$Style, NCData.sf$R_AC),
p = .60, list = FALSE)

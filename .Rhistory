# Save data frame(s)
# Point to a folder on your computer.
# Remember to change direction of the slash sign.
# Have to specify file type (in this case, .csv).
# csv takes up less space, but does not preserve formatting or formulas
write.csv(raven.1, file = "", row.names = FALSE)
number <- c(8, 2, 81, 98, 9)
ht <- c(6.2, 6.1, 5.11, 6.1, 6.1)
wt <- c(212, 196, 191, 336, 183)
col <- c("Louisville", "Utah", "Tenn-Mart", "MSU", "Texas")
raven.1 <- data.frame(name, number, ht, wt, col)
raven.1
# or view table using view() or click Data in Environment window
# view in ascending/descending order by clicking arrow on header
# Could use colnames() function to change column names. Google it.
colnames(raven.1) <- c("Player", "Jersey", "Height", "Weight", "College")
posn <- c("QB", "QB", "WR", "DT", "K")
raven.2 <- cbind(raven.1, posn)
raven.2
# Save data frame(s)
# Point to a folder on your computer.
# Remember to change direction of the slash sign.
# Have to specify file type (in this case, .csv).
# csv takes up less space, but does not preserve formatting or formulas
write.csv(raven.1, file = "C:\Users\brook\OneDrive\Desktop\CPLN 501\Labs\Module 2\Intro to R", row.names = FALSE)
# Save data frame(s)
# Point to a folder on your computer.
# Remember to change direction of the slash sign.
# Have to specify file type (in this case, .csv).
# csv takes up less space, but does not preserve formatting or formulas
write.csv(raven.1, file = "C:/Users/brook/OneDrive/Desktop/CPLN 501/Labs/Module 2/Intro to R", row.names = FALSE)
# Save data frame(s)
# Point to a folder on your computer.
# Remember to change direction of the slash sign.
# Have to specify file type (in this case, .csv).
# csv takes up less space, but does not preserve formatting or formulas
write.csv(raven.1, file = "C:/Users/brook/OneDrive/Desktop/CPLN 501/Labs/Module 2/Intro to R", row.names = FALSE)
# Save data frame(s)
# Point to a folder on your computer.
# Remember to change direction of the slash sign.
# Have to specify file type (in this case, .csv).
# csv takes up less space, but does not preserve formatting or formulas
write.csv(raven.1, file = "C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs\\Module 2", row.names = FALSE)
# Save data frame(s)
# Point to a folder on your computer.
# Remember to change direction of the slash sign.
# Have to specify file type (in this case, .csv).
# csv takes up less space, but does not preserve formatting or formulas
write.csv(raven.1, file = "C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs\\Module 2.csv", row.names = FALSE)
# read in data
# Copy file path (shift + right click on PC)
# On Mac https://apple.stackexchange.com/questions/338898/how-to-copy-path-of-a-file-in-mac-os/338899
NewData <- read.csv(""C:\Users\brook\OneDrive\Desktop\CPLN 501\Labs\Module 2.csv"", header=TRUE) # Assign data frame to an object
# read in data
# Copy file path (shift + right click on PC)
# On Mac https://apple.stackexchange.com/questions/338898/how-to-copy-path-of-a-file-in-mac-os/338899
NewData <- read.csv("C:\Users\brook\OneDrive\Desktop\CPLN 501\Labs\Module 2.csv", header=TRUE) # Assign data frame to an object
# read in data
# Copy file path (shift + right click on PC)
# On Mac https://apple.stackexchange.com/questions/338898/how-to-copy-path-of-a-file-in-mac-os/338899
NewData <- read.csv("C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs\\Module 2.csv", header=TRUE) # Assign data frame to an object
# store the data frame in a new object called R Data (rda file)
# allows saving multiple data frames and objects in one file
save(raven.1, raven.2, NewData,
file = "C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs\\Ravens1.csv")
save(raven.1, raven.2, NewData,
file = "C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs\\Ravens1.csv")
rm(list = ls())
load("C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs\\Ravens1.csv")
# Use R as calculator
8 + (2 - 1) * 5 / (3^2) + sqrt(4) - 8^(1/3) + log(4) - exp(2)
number <- c(33, 13, 81, 26, 96)
ht <- c(6.2, 6.0, 6.2, 6.0, 6.3)
number * 2
number + ht
log(number)
exp(number)
save(raven.1, raven.2, NewData,
file = "C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs\\Ravens1.rda")
rm(list = ls())
load("C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs\\Ravens1.rda")
# Use R as calculator
8 + (2 - 1) * 5 / (3^2) + sqrt(4) - 8^(1/3) + log(4) - exp(2)
number <- c(33, 13, 81, 26, 96)
ht <- c(6.2, 6.0, 6.2, 6.0, 6.3)
number * 2
number + ht
log(number)
exp(number)
number <- c(33, 13, 81, 26, 96)
ht <- c(6.2, 6.0, 6.2, 6.0, 6.3)
number * 2
number + ht
log(number)
exp(number)
#Working with data frame####
# File > Open File or use command
rm(list=ls())
setwd("C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs\\Module 2\\Intro to R") # Path to the folder on your computer. For PC- change the default \ to /
setwd("C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs") # Path to the folder on your computer. For PC- change the default \ to /
setwd("C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs") # Path to the folder on your computer. For PC- change the default \ to /
# Convenient for you and others
# because we set working directory, we do not need to type the whole file path when saving or loading files.
NewData <- read.csv("Module 2", header=TRUE)
# Convenient for you and others
# because we set working directory, we do not need to type the whole file path when saving or loading files.
NewData <- read.csv("Module 2.csv", header=TRUE)
load("D:/Fall2022/quant/handouts/baltimore_census.rda")
load("D:/Fall2022/quant/handouts/baltimore_census.rda")
load("C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labsbaltimore_census.rda")
load("C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\baltimore_census.rda")
load("C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs\\baltimore_census.rda")
# Data inspection
# Clicking on data frame in Environment pane shows the table
str(baltimore) # Structure of data.
#data class: number v. character
#can't perform mathematical operations on character or factor
#need to convert to numeric before doing mathematical operations
dim(baltimore) # Dimension of data set, i.e., No. of rows and cols.
length(baltimore) # Shows the no. of cols.
# We could use the values these functions return
head(baltimore) # a snippet
head(baltimore,3) # First 3 rows for every column in dat2010.
tail(baltimore,4) # Last 4 rows
names(baltimore) # Shows all the column names.
summary(baltimore) # Shows summary statistics. Can use it on single column.
# $column name gives access to single column.
baltimore$pov_moe
table(baltimore$fake_region) # Frequency table
table(baltimore$fake_region)/length(baltimore$area) # Proportion
table(baltimore$fake_region, baltimore$pop_quantile) # Cross table
# Basic calculation
sum(baltimore$area)
mean(baltimore$area)
median(baltimore$area)
sd(baltimore$area) # standard deviation
max(baltimore$area) # maximum
min(baltimore$area) # minimum
# subscripting (access certain element by specifying its location like coordinates)
# [row#, column#]
baltimore[1,2] # Calls the value in the first row of the second col.
# subscripting (access certain element by specifying its location like coordinates)
# [row#, column#]
baltimore[1,2] # Calls the value in the first row of the second col.
glimpse(baltimore)
View(baltimore)
new.bmore[2,1] <- 99999 # change the value in cell [2,1] to 99999
baltimore[1,2] # Calls the value in the first row of the second col.
new.bmore[2,1] <- 99999
table(baltimore$fake_region) # Frequency table
table(baltimore$fake_region)/length(baltimore$area) # Proportion
table(baltimore$fake_region, baltimore$pop_quantile)
# Basic calculation
sum(baltimore$area)
mean(baltimore$area)
median(baltimore$area)
baltimore[2,1] <- 99999 # change the value in cell [2,1] to 99999
baltimore[2,] # Access 2nd row for all columns
baltimore[,2] # Access values in 2nd column
baltimore[,c(1,2)] # Access only columns 1 and 2
baltimore[,c(1:4)] # Access columns 1 through 4 using :
new.bmore <- baltimore[,-c(3:5)] # Store selected columns (- means deselect) in a new object/data frame
baltimore[,c(1,2)] # Access only columns 1 and 2
baltimore[,c(1:4)] # Access columns 1 through 4 using :
new.bmore <- baltimore[,-c(3:5)]
# subsetting data
pop.bmore <- baltimore[baltimore$population > 2000 & baltimore$pop_poverty < 500, ]
pop.bmore <- baltimore[baltimore$pop_poverty == 0, ] # == means is exactly equal to
pop.bmore <- baltimore[baltimore$pop_poverty != 0, ] # != means not equal to
# subsetting data
pop.bmore <- baltimore[baltimore$population > 2000 & baltimore$pop_poverty < 500, ]
pop.bmore <- baltimore[baltimore$pop_poverty == 0, ] # == means is exactly equal to
pop.bmore <- baltimore[baltimore$population > 2000 | baltimore$population < 500, ] # | means "or"
which(baltimore[,"pop_poverty"] >= 3000) # which rows meet certain condition
length(which(baltimore[,3] >= 3000)) #how many rows meet certain condition
# Working with columns
baltimore$Pop_Density <- baltimore$population/baltimore$area # Column calculation
baltimore$newcol <- "this is a new column" # Create a new column with same values
#Categorization and tidyverse####
baltimore$population_cat[baltimore$population >= 2000] <- "high" # All items greater than or equal to 5000.
baltimore$population_cat_1[baltimore$population < median(baltimore$population)] <- "low" # subsetting records meeting condition and labeling them low
baltimore$region_cat_2[baltimore$fake_region == "east" |
baltimore$fake_region == "west"] <- "region 1" # recategorizing characters
#Categorization and tidyverse####
baltimore$population_cat[baltimore$population >= 2000] <- "high" # All items greater than or equal to 5000.
baltimore$population_cat_1[baltimore$population < median(baltimore$population)] <- "low" # subsetting records meeting condition and labeling them low
baltimore$region_cat_2[baltimore$fake_region == "east" |
baltimore$fake_region == "west"] <- "region 1" # recategorizing characters
# We've seen how to do things in base R...
# Now let's use some functions that are not in base R
# These functions are in a package (plug-in) called tidyverse
# install.packages("tidyverse") # Only need to install the package once
library(tidyverse) # In every new session, call the package using library
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory"
NC_Data = st_read("https://raw.githubusercontent.com/mafichman/MUSA_508_Lab/main/Midterm/data/2022/studentData.geojson")
head(NC_Data)
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
Schools = st_read("Schools_(view_of_points).geojson")
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(ggplot2)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory"
NC_Data = st_read("https://raw.githubusercontent.com/mafichman/MUSA_508_Lab/main/Midterm/data/2022/studentData.geojson")
head(NC_Data)
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
Schools <- st_read("Schools_(view_of_points).geojson")
View(Schools)
TOD <- st_read("Transit_Oriented_Development_Areas.geojson")
View(TOD)
Grocery <- st_read("Grocery_Stores_(points).geojson")
Shopping <- st_read("Grocery_Stores_(points).geojson")
Improvements <- st_read("Capital_Improvement_Projects_Points.geojson")
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(ggplot2)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory"
NC_Data = st_read("https://raw.githubusercontent.com/mafichman/MUSA_508_Lab/main/Midterm/data/2022/studentData.geojson")
head(NC_Data)
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
#nhoods <-
#st_read("http://bostonopendata-boston.opendata.arcgis.com/datasets/3525b0ee6e6b427f9aab5d0a1d0a1a28_0.geojson") %>%
# st_transform('ESRI:102286')
#boston <-
#read.csv(file.path(root.dir,"/Chapter3_4/bostonHousePriceData_clean.csv"))
Schools <- st_read("Schools_(view_of_points).geojson")
TOD <- st_read("Transit_Oriented_Development_Areas.geojson")
Grocery <- st_read("Grocery_Stores_(points).geojson")
Shopping <- st_read("Grocery_Stores_(points).geojson")
Improvements <- st_read("Capital_Improvement_Projects_Points.geojson")
NCData.sf <-
NC_Data %>%
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102286')
#bostonCrimes <- read.csv(file.path(root.dir,"/Chapter3_4/bostonCrimes.csv"))
# finding counts by group
NC_Data %>%
group_by(bldggrade) %>%
summarize(count = n()) %>%
arrange(-count) %>% top_n(10) %>%
kable() %>%
kable_styling()
NC_Buffers <-
rbind(
st_buffer(NC_Data, 2640) %>%
mutate(Legend = "Buffer") %>%
dplyr::select(Legend),
st_union(st_buffer(NC_Data, 2640)) %>%
st_sf() %>%
mutate(Legend = "Unioned Buffer"))
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(ggplot2)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory"
NC_Data = st_read("https://raw.githubusercontent.com/mafichman/MUSA_508_Lab/main/Midterm/data/2022/studentData.geojson")
head(NC_Data)
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
ImprovProj <-
st_read("Capital_Improvement_Projects.geojson") %>%
st_transform('ESRI:102286')
ImprovProj <-
st_read("Capital_Improvement_Projects_Points.geojson") %>%
st_transform('ESRI:102286')
ImprovProj <-
st_read("Capital_Improvement_Projects_Points.geojson") %>%
st_transform('ESRI:102286')
NCData.sf <-
NC_Data %>%
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102286')
ImproveProj.sf <-
ImprovProj %>%
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102286')
ImproveProj.sf <-
Grocery %>%
filter(PID > "1",
Lat > -1) %>%
dplyr::select(Lat, Long) %>%
na.omit() %>%
st_as_sf(coords = c("Long", "Lat"), crs = "EPSG:4326") %>%
st_transform('ESRI:102286') %>%
distinct()
View(ImprovProj)
ImproveProj.sf <-
ImprovProj %>%
filter(OBJECTID > "1",
Lat > -1) %>%
dplyr::select(Lat, Long) %>%
na.omit() %>%
st_as_sf(coords = c("Long", "Lat"), crs = "EPSG:4326") %>%
st_transform('ESRI:102286') %>%
distinct()
ImproveProj.sf <-
ImprovProj %>%
filter(OBJECTID > "1",
Lat > -1)
ImproveProj.sf <-
ImprovProj %>%
dplyr::select(Lat, Long) %>%
na.omit() %>%
st_as_sf(coords = c("Long", "Lat"), crs = "EPSG:4326") %>%
st_transform('ESRI:102286') %>%
distinct()
# Counts of crime per buffer of house sale
ImproveProj.sf$OBJECTID.Buffer <- ImprProj.sf %>%
st_buffer(660) %>%
aggregate(mutate(ImproveProj.sf, counter = 1),., sum) %>%
pull(counter)
# Counts of crime per buffer of house sale
ImproveProj.sf$OBJECTID.Buffer <- ImprProj.sf %>%
st_buffer(660) %>%
aggregate(mutate(ImproveProj.sf, counter = 1),., sum) %>%
pull(counter)
# Counts of crime per buffer of house sale
ImproveProj.sf$OBJECTID.Buffer <- ImproveProj.sf %>%
st_buffer(660) %>%
aggregate(mutate(ImproveProj.sf, counter = 1),., sum) %>%
pull(counter)
ImproveProj.sf$OBJECTID.Buffer <- ImproveProj.sf %>%
st_buffer(660) %>%
aggregate(mutate(ImproveProj.sf, counter = 1),., sum) %>%
pull(counter)
Groceries <- st_read("Grocery_Stores_(points).geojson")
st_transform('ESRI:102286)
Groceries.sf <- Groceries %>%
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102286)
Groceries.sf <-
Groceries %>%
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102286')
View(Groceries)
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(ggplot2)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory"
NC_Data = st_read("https://raw.githubusercontent.com/mafichman/MUSA_508_Lab/main/Midterm/data/2022/studentData.geojson")
head(NC_Data)
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
ImprovProj <-
st_read("Capital_Improvement_Projects_Points.geojson") %>%
st_transform('ESRI:102286')
Groceries <- st_read("Grocery_Stores_(points).geojson")
NCData.sf <-
NC_Data %>%
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102286')
ImproveProj.sf <-
ImprovProj %>%
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102286')
Groceries.sf <-
Groceries %>%
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102286')
# finding counts by group
NC_Data %>%
group_by(bldggrade) %>%
summarize(count = n()) %>%
arrange(-count) %>% top_n(10) %>%
kable() %>%
kable_styling()
Groceries.sf <-
Groceries %>%
filter(PID > "1",
Lat > -1) %>%
dplyr::select(Lat, Long) %>%
na.omit() %>%
st_as_sf(coords = c("Long", "Lat"), crs = "EPSG:4326") %>%
st_transform('ESRI:102286') %>%
distinct()
Groceries.sf <-
Groceries %>%
filter(PID > "1") %>%
dplyr::select(Lat, Long) %>%
na.omit() %>%
st_as_sf(coords = c("Long", "Lat"), crs = "EPSG:4326") %>%
st_transform('ESRI:102286') %>%
distinct()
Groceries.sf <-
Groceries %>%
filter(PID > "1") %>%
na.omit() %>%
st_as_sf(coords = c("Long", "Lat"), crs = "EPSG:4326") %>%
st_transform('ESRI:102286') %>%
distinct()
# Counts of crime per buffer of house sale
Groceries.sf$OBJECTID.Buffer <- Groceries.sf %>%
st_buffer(660) %>%
aggregate(mutate(Groceries.sf, counter = 1),., sum) %>%
pull(counter)
# Counts of crime per buffer of house sale
Groceries.sf$OBJECTID.Buffer <- Groceries.sf %>%
st_buffer(660) %>%
aggregate(mutate(Groceries.sf, counter = 1),., sum) %>%
pull(counter)
Groceries.sf <-
Groceries.sf %>%
mutate(
grocery_nn1 = nn_function(st_coordinates(NCData.sf),
st_coordinates(Groceries.sf), k = 1),
grocery_nn2 = nn_function(st_coordinates(NCData.sf),
st_coordinates(Groceries.sf), k = 2),
grocery_nn3 = nn_function(st_coordinates(NCData.sf),
st_coordinates(Groceries.sf), k = 3),
grocery_nn4 = nn_function(st_coordinates(NCData.sf),
st_coordinates(Groceries.sf), k = 4),
grocery_nn5 = nn_function(st_coordinates(NCData.sf),
st_coordinates(Groceries.sf), k = 5))
Groceries.sf$OBJECTID.Buffer <- Groceries.sf %>%
st_buffer(660) %>%
aggregate(mutate(Groceries.sf, counter = 1),., sum) %>%
pull(counter)
ggplot() + geom_sf(data = Groceries, fill = "grey40") +
stat_density2d(data = data.frame(st_coordinates(Groceries.sf)),
aes(X, Y, fill = ..level.., alpha = ..level..),
size = 0.01, bins = 40, geom = 'polygon') +
scale_fill_gradient(low = "#25CB10", high = "#FA7800", name = "Density") +
scale_alpha(range = c(0.00, 0.35), guide = "none") +
labs(title = "Density of Grocery Stores, NC") +
mapTheme()
## Plot assault density
ggplot() + geom_sf(data = Groceries, fill = "grey40") +
stat_density2d(data = data.frame(st_coordinates(Groceries.sf)),
aes(X, Y, fill = ..level.., alpha = ..level..),
size = 0.01, bins = 40, geom = 'polygon') +
scale_fill_gradient(low = "#25CB10", high = "#FA7800", name = "Density") +
scale_alpha(range = c(0.00, 0.35), guide = "none") +
labs(title = "Density of Grocery Stores, NC") +
mapTheme()

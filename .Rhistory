mutate(Age = 2015 - YR_BUILT) %>%
dplyr::select(SalePrice, starts_with("crime_")) %>%
filter(SalePrice <= 1000000) %>%
gather(Variable, Value, -SalePrice) %>%
ggplot(aes(Value, SalePrice)) +
geom_point(size = .5) + geom_smooth(method = "lm", se=F, colour = "#FA7800") +
facet_wrap(~Variable, nrow = 1, scales = "free") +
labs(title = "Price as a function of continuous variables") +
plotTheme()
View(NC_Data.sf)
NCData.test <- NCData.sf[-inTrain,]
inTrain <- createDataPartition(
y = paste(NCData.sf$Name, NCData.sf$NUM_FLOORS.cat,
NCData.sf$Style, NCData.sf$R_AC),
p = .60, list = FALSE)
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory"
NC_Data = st_read("https://raw.githubusercontent.com/mafichman/MUSA_508_Lab/main/Midterm/data/2022/studentData.geojson")
head(NC_Data)
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
#nhoods <-
#st_read("http://bostonopendata-boston.opendata.arcgis.com/datasets/3525b0ee6e6b427f9aab5d0a1d0a1a28_0.geojson") %>%
# st_transform('ESRI:102286')
#boston <-
#read.csv(file.path(root.dir,"/Chapter3_4/bostonHousePriceData_clean.csv"))
NCData.sf <-
NC_Data %>%
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102286')
#bostonCrimes <- read.csv(file.path(root.dir,"/Chapter3_4/bostonCrimes.csv"))
# finding counts by group
NC_Data %>%
group_by(bldggrade) %>%
summarize(count = n()) %>%
arrange(-count) %>% top_n(10) %>%
kable() %>%
kable_styling()
inTrain <- createDataPartition(
y = paste(NCData.sf$Name, NCData.sf$NUM_FLOORS.cat,
NCData.sf$Style, NCData.sf$R_AC),
p = .60, list = FALSE)
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory"
NC_Data = st_read("https://raw.githubusercontent.com/mafichman/MUSA_508_Lab/main/Midterm/data/2022/studentData.geojson")
head(NC_Data)
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
#nhoods <-
#st_read("http://bostonopendata-boston.opendata.arcgis.com/datasets/3525b0ee6e6b427f9aab5d0a1d0a1a28_0.geojson") %>%
# st_transform('ESRI:102286')
#boston <-
#read.csv(file.path(root.dir,"/Chapter3_4/bostonHousePriceData_clean.csv"))
NCData.sf <-
NC_Data %>%
st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
st_transform('ESRI:102286')
#bostonCrimes <- read.csv(file.path(root.dir,"/Chapter3_4/bostonCrimes.csv"))
# finding counts by group
NC_Data %>%
group_by(bldggrade) %>%
summarize(count = n()) %>%
arrange(-count) %>% top_n(10) %>%
kable() %>%
kable_styling()
# ggplot, reorder
# Mapping data
ggplot() +
geom_sf(data = nhoods, fill = "grey40") +
#geom_sf(data = boston.sf, aes(colour = q5(PricePerSq)),
show.legend = "point", size = .75) +
# ggplot, reorder
# Mapping data
ggplot() +
geom_sf(data = nhoods, fill = "grey40") +
#geom_sf(data = NC_Data.sf, aes(colour = q5(PricePerSq)),
show.legend = "point", size = .75) +
# Mapping data
ggplot() +
geom_sf(data = NC_Data, fill = "grey40") +
geom_sf(data = NC_Data.sf, aes(colour = q5(price)),
show.legend = "point", size = .75) +
scale_colour_manual(values = palette5,
labels= qBr(NC_Data, "price"),
name="Quintile\nBreaks") +
labs(title="Price Per Square Foot, North Carolina") +
mapTheme()
## Home Features cor
st_drop_geometry(NCData.sf) %>%
mutate(Age = 2022 - yearbuilt) %>%
dplyr::select(price, heatedarea, Age, shape_Area) %>%
filter(price <= 1000000, Age < 500) %>%
gather(Variable, Value, -price) %>%
ggplot(aes(Value, price)) +
geom_point(size = .5) + geom_smooth(method = "lm", se=F, colour = "#FA7800") +
facet_wrap(~Variable, ncol = 3, scales = "free") +
labs(title = "Price as a function of continuous variables") +
plotTheme()
# finding counts by group
NC_Data %>%
group_by(bldggrade) %>%
st_drop_geometry() %>%
summarize(count = n()) %>%
arrange(-count) %>%
head(10) %>%
kable() %>%
kable_styling()
numericVars <-
select_if(st_drop_geometry(NCData.sf), is.numeric) %>% na.omit()
ggcorrplot(
round(cor(numericVars), 1),
p.mat = cor_pmat(numericVars),
colors = c("#25CB10", "white", "#FA7800"),
type="lower",
insig = "blank") +
labs(title = "Correlation across numeric variables")
ggcorrplot(
round(cor(numericVars), 1),
p.mat = cor_pmat(numericVars),
colors = c("#25CB10", "white", "#FA7800"),
type="lower",
insig = "blank") +
labs(title = "Correlation across numeric variables")
# yet another way to plot the correlation plot using the corrr library
numericVars %>%
correlate() %>%
autoplot() +
geom_text(aes(label = round(r,digits=2)),size = 2)
nc_sub_200k <- st_drop_geometry(NCData.sf) %>%
filter(price <= 2000000)
cor.test(nc_sub_200k$heatedarea,
nc_sub_200k$price,
method = "pearson")
ggcorrplot(
round(cor(numericVars), 1),
p.mat = cor_pmat(numericVars),
colors = c("#25CB10", "white", "#FA7800"),
type="lower",
insig = "blank") +
labs(title = "Correlation across numeric variables")
nc_sub_200k <- st_drop_geometry(NCData.sf) %>%
filter(price <= 2000000)
cor.test(nc_sub_200k$yearbuilt,
nc_sub_200k$price,
method = "pearson")
cor.test(nc_sub_200k$bedrooms,
nc_sub_200k$price,
method = "pearson")
ggscatter(nc_sub_200k,
x = "bedrooms",
y = "price",
add = "reg.line") +
stat_cor(label.y = 2500000)
livingReg <- lm(price ~ heatedarea, data = nc_sub_200k)
summary(livingReg)
ggscatter(nc_sub_200k,
x = "heatedarea",
y = "price",
add = "reg.line") +
stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "~`,`~")), label.y = 2500000) +
stat_regline_equation(label.y = 2250000)
livingReg <- lm(price ~ bedrooms, data = nc_sub_200k)
Bedrooms <- lm(price ~ bedrooms, data = nc_sub_200k)
summary(bedrooms)
Bedrooms <- lm(price ~ Bedrooms, data = nc_sub_200k)
Bedrooms <- lm(price ~ bedrooms, data = nc_sub_200k)
summary(Bedrooms)
ggscatter(nc_sub_200k,
x = "bedrooms",
y = "price",
add = "reg.line") +
stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "~`,`~")), label.y = 2500000) +
stat_regline_equation(label.y = 2250000)
Zipcode <- lm(price ~ Zipcode, data = nc_sub_200k)
Zipcode <- lm(price ~ Zipcode, data = nc_sub_200k)
Zipcode <- lm(price ~ zipcode, data = nc_sub_200k)
summary(Zipcode)
ggscatter(nc_sub_200k,
x = "Zipcode",
y = "price",
add = "reg.line") +
stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "~`,`~")), label.y = 2500000) +
stat_regline_equation(label.y = 2250000)
Zipcode <- lm(price ~ zipcode, data = nc_sub_200k)
Zipcode <- lm(price ~ zipcode, data = nc_sub_200k)
summary(Zipcode)
summary(Zipcode)
ggscatter(nc_sub_200k,
x = "Zipcode",
y = "price",
add = "reg.line") +
stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "~`,`~")), label.y = 2500000) +
stat_regline_equation(label.y = 2250000)
sum(1,2,3)
# Creating new objects
numberA <- 3  # appear in Environment pane
numberA
numberB <- 2
numberA + numberB # operate with objects
sumAandB <- numberA + numberB # store value in object
sumAandB
# an object does not have to be a number
# it could be texts, a table, a statistical model, an image, etc.
Penn <- "University of Pennsylvania"
Penn
Penn <- University of Pennsylvania  # doesn't work if texts are not quoted
# unless "text" is an existing object...
upenn <- Penn
upenn
# Naming convention
U.P. <- "Urban Planning" # full stops are fine
Urban_Planning <- "Urban Planning" # Underscores are fine
number1 <- "Number 1" # Numbers are fine
1number <- "number 1" # Not okay! Can't start with numbers, which means it cannot be all numeric like 123
name <- c("Lamar Jackson", "Tyler Huntley", # wrap texts in quotes
"Jaylon Moore", "Brandon Williams",
"Justin Tucker")
# changing line is fine but make sure R knows there is something on the next line
name
number <- c(8, 2, 81, 98, 9)
ht <- c(6.2, 6.1, 5.11, 6.1, 6.1)
wt <- c(212, 196, 191, 336, 183)
col <- c("Louisville", "Utah", "Tenn-Mart", "MSU", "Texas")
# Combine
raven.1 <- data.frame(name, number, ht, wt, col)
raven.1
# or view table using view() or click Data in Environment window
# view in ascending/descending order by clicking arrow on header
# Could use colnames() function to change column names. Google it.
colnames(raven.1) <- c("Player", "Jersey", "Height", "Weight", "College")
# Add a column called posn
posn <- c("QB", "QB", "WR", "DT", "K")
raven.2 <- cbind(raven.1, posn)
raven.2
# Save data frame(s)
# Point to a folder on your computer.
# Remember to change direction of the slash sign.
# Have to specify file type (in this case, .csv).
# csv takes up less space, but does not preserve formatting or formulas
write.csv(raven.1, file = "", row.names = FALSE)
number <- c(8, 2, 81, 98, 9)
ht <- c(6.2, 6.1, 5.11, 6.1, 6.1)
wt <- c(212, 196, 191, 336, 183)
col <- c("Louisville", "Utah", "Tenn-Mart", "MSU", "Texas")
raven.1 <- data.frame(name, number, ht, wt, col)
raven.1
# or view table using view() or click Data in Environment window
# view in ascending/descending order by clicking arrow on header
# Could use colnames() function to change column names. Google it.
colnames(raven.1) <- c("Player", "Jersey", "Height", "Weight", "College")
posn <- c("QB", "QB", "WR", "DT", "K")
raven.2 <- cbind(raven.1, posn)
raven.2
# Save data frame(s)
# Point to a folder on your computer.
# Remember to change direction of the slash sign.
# Have to specify file type (in this case, .csv).
# csv takes up less space, but does not preserve formatting or formulas
write.csv(raven.1, file = "C:\Users\brook\OneDrive\Desktop\CPLN 501\Labs\Module 2\Intro to R", row.names = FALSE)
# Save data frame(s)
# Point to a folder on your computer.
# Remember to change direction of the slash sign.
# Have to specify file type (in this case, .csv).
# csv takes up less space, but does not preserve formatting or formulas
write.csv(raven.1, file = "C:/Users/brook/OneDrive/Desktop/CPLN 501/Labs/Module 2/Intro to R", row.names = FALSE)
# Save data frame(s)
# Point to a folder on your computer.
# Remember to change direction of the slash sign.
# Have to specify file type (in this case, .csv).
# csv takes up less space, but does not preserve formatting or formulas
write.csv(raven.1, file = "C:/Users/brook/OneDrive/Desktop/CPLN 501/Labs/Module 2/Intro to R", row.names = FALSE)
# Save data frame(s)
# Point to a folder on your computer.
# Remember to change direction of the slash sign.
# Have to specify file type (in this case, .csv).
# csv takes up less space, but does not preserve formatting or formulas
write.csv(raven.1, file = "C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs\\Module 2", row.names = FALSE)
# Save data frame(s)
# Point to a folder on your computer.
# Remember to change direction of the slash sign.
# Have to specify file type (in this case, .csv).
# csv takes up less space, but does not preserve formatting or formulas
write.csv(raven.1, file = "C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs\\Module 2.csv", row.names = FALSE)
# read in data
# Copy file path (shift + right click on PC)
# On Mac https://apple.stackexchange.com/questions/338898/how-to-copy-path-of-a-file-in-mac-os/338899
NewData <- read.csv(""C:\Users\brook\OneDrive\Desktop\CPLN 501\Labs\Module 2.csv"", header=TRUE) # Assign data frame to an object
# read in data
# Copy file path (shift + right click on PC)
# On Mac https://apple.stackexchange.com/questions/338898/how-to-copy-path-of-a-file-in-mac-os/338899
NewData <- read.csv("C:\Users\brook\OneDrive\Desktop\CPLN 501\Labs\Module 2.csv", header=TRUE) # Assign data frame to an object
# read in data
# Copy file path (shift + right click on PC)
# On Mac https://apple.stackexchange.com/questions/338898/how-to-copy-path-of-a-file-in-mac-os/338899
NewData <- read.csv("C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs\\Module 2.csv", header=TRUE) # Assign data frame to an object
# store the data frame in a new object called R Data (rda file)
# allows saving multiple data frames and objects in one file
save(raven.1, raven.2, NewData,
file = "C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs\\Ravens1.csv")
save(raven.1, raven.2, NewData,
file = "C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs\\Ravens1.csv")
rm(list = ls())
load("C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs\\Ravens1.csv")
# Use R as calculator
8 + (2 - 1) * 5 / (3^2) + sqrt(4) - 8^(1/3) + log(4) - exp(2)
number <- c(33, 13, 81, 26, 96)
ht <- c(6.2, 6.0, 6.2, 6.0, 6.3)
number * 2
number + ht
log(number)
exp(number)
save(raven.1, raven.2, NewData,
file = "C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs\\Ravens1.rda")
rm(list = ls())
load("C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs\\Ravens1.rda")
# Use R as calculator
8 + (2 - 1) * 5 / (3^2) + sqrt(4) - 8^(1/3) + log(4) - exp(2)
number <- c(33, 13, 81, 26, 96)
ht <- c(6.2, 6.0, 6.2, 6.0, 6.3)
number * 2
number + ht
log(number)
exp(number)
number <- c(33, 13, 81, 26, 96)
ht <- c(6.2, 6.0, 6.2, 6.0, 6.3)
number * 2
number + ht
log(number)
exp(number)
#Working with data frame####
# File > Open File or use command
rm(list=ls())
setwd("C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs\\Module 2\\Intro to R") # Path to the folder on your computer. For PC- change the default \ to /
setwd("C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs") # Path to the folder on your computer. For PC- change the default \ to /
setwd("C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs") # Path to the folder on your computer. For PC- change the default \ to /
# Convenient for you and others
# because we set working directory, we do not need to type the whole file path when saving or loading files.
NewData <- read.csv("Module 2", header=TRUE)
# Convenient for you and others
# because we set working directory, we do not need to type the whole file path when saving or loading files.
NewData <- read.csv("Module 2.csv", header=TRUE)
load("D:/Fall2022/quant/handouts/baltimore_census.rda")
load("D:/Fall2022/quant/handouts/baltimore_census.rda")
load("C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labsbaltimore_census.rda")
load("C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\baltimore_census.rda")
load("C:\\Users\\brook\\OneDrive\\Desktop\\CPLN 501\\Labs\\baltimore_census.rda")
# Data inspection
# Clicking on data frame in Environment pane shows the table
str(baltimore) # Structure of data.
#data class: number v. character
#can't perform mathematical operations on character or factor
#need to convert to numeric before doing mathematical operations
dim(baltimore) # Dimension of data set, i.e., No. of rows and cols.
length(baltimore) # Shows the no. of cols.
# We could use the values these functions return
head(baltimore) # a snippet
head(baltimore,3) # First 3 rows for every column in dat2010.
tail(baltimore,4) # Last 4 rows
names(baltimore) # Shows all the column names.
summary(baltimore) # Shows summary statistics. Can use it on single column.
# $column name gives access to single column.
baltimore$pov_moe
table(baltimore$fake_region) # Frequency table
table(baltimore$fake_region)/length(baltimore$area) # Proportion
table(baltimore$fake_region, baltimore$pop_quantile) # Cross table
# Basic calculation
sum(baltimore$area)
mean(baltimore$area)
median(baltimore$area)
sd(baltimore$area) # standard deviation
max(baltimore$area) # maximum
min(baltimore$area) # minimum
# subscripting (access certain element by specifying its location like coordinates)
# [row#, column#]
baltimore[1,2] # Calls the value in the first row of the second col.
# subscripting (access certain element by specifying its location like coordinates)
# [row#, column#]
baltimore[1,2] # Calls the value in the first row of the second col.
glimpse(baltimore)
View(baltimore)
new.bmore[2,1] <- 99999 # change the value in cell [2,1] to 99999
baltimore[1,2] # Calls the value in the first row of the second col.
new.bmore[2,1] <- 99999
table(baltimore$fake_region) # Frequency table
table(baltimore$fake_region)/length(baltimore$area) # Proportion
table(baltimore$fake_region, baltimore$pop_quantile)
# Basic calculation
sum(baltimore$area)
mean(baltimore$area)
median(baltimore$area)
baltimore[2,1] <- 99999 # change the value in cell [2,1] to 99999
baltimore[2,] # Access 2nd row for all columns
baltimore[,2] # Access values in 2nd column
baltimore[,c(1,2)] # Access only columns 1 and 2
baltimore[,c(1:4)] # Access columns 1 through 4 using :
new.bmore <- baltimore[,-c(3:5)] # Store selected columns (- means deselect) in a new object/data frame
baltimore[,c(1,2)] # Access only columns 1 and 2
baltimore[,c(1:4)] # Access columns 1 through 4 using :
new.bmore <- baltimore[,-c(3:5)]
# subsetting data
pop.bmore <- baltimore[baltimore$population > 2000 & baltimore$pop_poverty < 500, ]
pop.bmore <- baltimore[baltimore$pop_poverty == 0, ] # == means is exactly equal to
pop.bmore <- baltimore[baltimore$pop_poverty != 0, ] # != means not equal to
# subsetting data
pop.bmore <- baltimore[baltimore$population > 2000 & baltimore$pop_poverty < 500, ]
pop.bmore <- baltimore[baltimore$pop_poverty == 0, ] # == means is exactly equal to
pop.bmore <- baltimore[baltimore$population > 2000 | baltimore$population < 500, ] # | means "or"
which(baltimore[,"pop_poverty"] >= 3000) # which rows meet certain condition
length(which(baltimore[,3] >= 3000)) #how many rows meet certain condition
# Working with columns
baltimore$Pop_Density <- baltimore$population/baltimore$area # Column calculation
baltimore$newcol <- "this is a new column" # Create a new column with same values
#Categorization and tidyverse####
baltimore$population_cat[baltimore$population >= 2000] <- "high" # All items greater than or equal to 5000.
baltimore$population_cat_1[baltimore$population < median(baltimore$population)] <- "low" # subsetting records meeting condition and labeling them low
baltimore$region_cat_2[baltimore$fake_region == "east" |
baltimore$fake_region == "west"] <- "region 1" # recategorizing characters
#Categorization and tidyverse####
baltimore$population_cat[baltimore$population >= 2000] <- "high" # All items greater than or equal to 5000.
baltimore$population_cat_1[baltimore$population < median(baltimore$population)] <- "low" # subsetting records meeting condition and labeling them low
baltimore$region_cat_2[baltimore$fake_region == "east" |
baltimore$fake_region == "west"] <- "region 1" # recategorizing characters
# We've seen how to do things in base R...
# Now let's use some functions that are not in base R
# These functions are in a package (plug-in) called tidyverse
# install.packages("tidyverse") # Only need to install the package once
library(tidyverse) # In every new session, call the package using library
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory"
NC_Data = st_read("https://raw.githubusercontent.com/mafichman/MUSA_508_Lab/main/Midterm/data/2022/studentData.geojson")
head(NC_Data)
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
Schools = st_read("Schools_(view_of_points).geojson")
# You can set some global options for knitting chunks
knitr::opts_chunk$set(echo = TRUE)
# Load some libraries
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(ggplot2)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
# functions and data directory"
NC_Data = st_read("https://raw.githubusercontent.com/mafichman/MUSA_508_Lab/main/Midterm/data/2022/studentData.geojson")
head(NC_Data)
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
Schools <- st_read("Schools_(view_of_points).geojson")
View(Schools)
TOD <- st_read("Transit_Oriented_Development_Areas.geojson")
View(TOD)
Grocery <- st_read("Grocery_Stores_(points).geojson")
Shopping <- st_read("Grocery_Stores_(points).geojson")
Improvements <- st_read("Capital_Improvement_Projects_Points.geojson")
